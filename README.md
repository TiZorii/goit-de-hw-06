# Topic "Spark Streaming"

Hello! How are you? I hope you're excited about a new challenge ðŸ˜‰  

Welcome to the homework assignment that will help you improve your practical skills in using Apache Kafka.  

The task is similar to what we had in the previous topic but far more interesting! ðŸ˜Š  

Today, you'll be tackling a typical IoT monitoring task.  

In this assignment, you'll need to create a program that processes a data stream from a Kafka topic, which is generated by sensors, and analyzes the data to write alerts to an alert-Kafka topic based on specific conditions.   

## Step-by-Step Instructions  

1. **Generating a Data Stream**:  
   The input data comes from a Kafka topic, the same as in the previous homework. Generate a data stream containing `id`, `temperature`, `humidity`, and `timestamp`. You can reuse the script and topic you created earlier.  

2. **Data Aggregation**:  
   Read the data stream generated in the first step. Using a **Sliding window** of 1-minute length, with a `sliding_interval` of 30 seconds and a `watermark duration` of 10 seconds, calculate the average temperature and humidity.  

3. **Getting Familiar with Alert Parameters**:  
   Your manager loves changing alert criteria. To avoid deploying code every time, the alert parameters are specified in a file:  
   `alerts_conditions.csv`  

   The file contains maximum and minimum values for temperature and humidity, along with messages and alert codes. Values `-999, -999` indicate that these limits are not used for the particular alert.  

   Take a look at the file; it should be intuitive. You need to read the data from the file and use it to configure alerts.  

4. **Building Alert Conditions**:  
   Once you've calculated the average values, determine whether they match the criteria specified in the file (hint: perform a cross join and apply filtering).  

5. **Writing Data to a Kafka Topic**:  
   Write the resulting alerts to an output Kafka topic.  
